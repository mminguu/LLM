{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e613d1d8",
   "metadata": {},
   "source": [
    "### ğŸ§  Attention(ì–´í…ì…˜)ì„ â€˜ì§„ì§œ ì‰½ê²Œâ€™ ì´í•´í•˜ê¸°\n",
    "\n",
    "#### ğŸ“Œ í•œ ì¤„ ì •ì˜\n",
    "> **ë¬¸ì¥ì—ì„œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ê³¨ë¼ ì§‘ì¤‘í•´ì„œ ë” ë˜‘ë˜‘í•˜ê²Œ ì´í•´í•˜ëŠ” ê¸°ìˆ **\n",
    "\n",
    "---\n",
    "\n",
    "#### 1ï¸âƒ£ ì™œ Attentionì´ ìƒê²¼ì„ê¹Œ? â€” Seq2Seqì˜ ë¬¸ì œ\n",
    "\n",
    "#### âœ”ï¸ í•µì‹¬ë§Œ ì§šê¸°\n",
    "Seq2Seq ë²ˆì—­ ëª¨ë¸ì€ **ê¸´ ë¬¸ì¥ì„ í•˜ë‚˜ì˜ ë²¡í„°ì— ëª¨ë‘ ì••ì¶•**í•˜ëŠ” ë°©ì‹ì´ì—ˆì–´.  \n",
    "í•˜ì§€ë§Œ ì‚¬ëŒë„ ê¸´ ê¸€ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì™¸ìš°ë©´ ì¤‘ìš”í•œ ë‚´ìš©ì´ ë¹ ì§€ë“¯,  \n",
    "ëª¨ë¸ë„ **ì¤‘ìš”í•œ ë‹¨ì–´ë¥¼ ìŠëŠ”ë‹¤.**\n",
    "\n",
    "#### âœ”ï¸ ì˜ˆì‹œ\n",
    "â€œë‚˜ëŠ” ì–´ì œ ë§ˆíŠ¸ì—ì„œ ì‚¬ê³¼ë‘ ìš°ìœ ë‘ ë¹µì´ë‘ ì¹˜í‚¨ì´ë‘ ì½œë¼ê¹Œì§€ ìƒ€ë‹¤â€\n",
    "\n",
    "â†’ ì´ë ‡ê²Œ ê¸´ ë¬¸ì¥ì„ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ì¤„ì´ë©´ ì•ìª½ì˜ **ì‚¬ê³¼**, **ìš°ìœ ** ì •ë³´ê°€ íë ¤ì§.\n",
    "\n",
    "#### âœ”ï¸ ê²°ë¡ \n",
    "> **ê¸´ ë¬¸ì¥ì¼ìˆ˜ë¡ Seq2SeqëŠ” ì •ë³´ê°€ ì†ì‹¤ëœë‹¤.**  \n",
    "\n",
    "â†’ ê·¸ë˜ì„œ â€œí•„ìš”í•  ë•Œ ê³¨ë¼ì„œ ë‹¤ì‹œ ë³´ìâ€ëŠ” ê°œë…ì¸ **Attention**ì´ ë“±ì¥í•¨.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2ï¸âƒ£ Attentionì´ ë­˜ í•˜ëŠ”ê°€? â€” â€˜ì§‘ì¤‘ë ¥â€™ ë¶€ì—¬\n",
    "\n",
    "#### âœ”ï¸ í•µì‹¬ ê°œë…\n",
    "Attentionì€  \n",
    "> **â€œì§€ê¸ˆ ë²ˆì—­í•˜ëŠ” ë‹¨ì–´ì™€ ê´€ë ¨ ìˆëŠ” ì…ë ¥ ë‹¨ì–´ì— ì§‘ì¤‘í•˜ëŠ” ê¸°ìˆ â€**\n",
    "\n",
    "ì „ì²´ ë¬¸ì¥ì„ ë‹¤ ë³´ì§€ë§Œ,  \n",
    "íŠ¹ì • ìˆœê°„ì—ëŠ” **ì¤‘ìš”í•œ ë‹¨ì–´ë§Œ í¬ê²Œ ë°˜ì˜**í•¨.\n",
    "\n",
    "#### âœ”ï¸ ì˜ˆì‹œ\n",
    "ë¬¸ì¥: â€œë‚˜ëŠ” ì‚¬ê³¼ë¥¼ ë¨¹ëŠ”ë‹¤â€\n",
    "\n",
    "- â€˜ì‚¬ê³¼â€™ë¥¼ ë²ˆì—­ â†’ appleì— ì§‘ì¤‘  \n",
    "- â€˜ë¨¹ëŠ”ë‹¤â€™ë¥¼ ë²ˆì—­ â†’ eatì— ì§‘ì¤‘  \n",
    "\n",
    "ì‚¬ëŒì´ ë²ˆì—­í•˜ëŠ” ë°©ì‹ê³¼ ë™ì¼í•¨.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3ï¸âƒ£ Query Â· Key Â· Value â€” ê°€ì¥ ì‰¬ìš´ ì„¤ëª…\n",
    "\n",
    "#### âœ”ï¸ ë¹„ìœ \n",
    "- **Query(ì§ˆë¬¸)**: ì§€ê¸ˆ ì–´ë–¤ ì •ë³´ê°€ í•„ìš”í•˜ì§€?  \n",
    "- **Key(ëª©ì°¨)**: ë‚˜ëŠ” ì´ëŸ° ì •ë³´ë¥¼ ê°–ê³  ìˆì–´  \n",
    "- **Value(ë‚´ìš©)**: ë‚´ê°€ ê°€ì§„ ì‹¤ì œ ì •ë³´ì•¼  \n",
    "\n",
    "#### âœ”ï¸ ë™ì‘ ê³¼ì •\n",
    "1. ë””ì½”ë”ê°€ í•„ìš”í•œ ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•´ **Query** ìƒì„±  \n",
    "2. ê° ë‹¨ì–´ëŠ” ìì‹ ì˜ íŠ¹ì§•ìœ¼ë¡œ **Key** ì œê³µ  \n",
    "3. Queryì™€ Keyë¥¼ ë¹„êµí•´ **ê´€ë ¨ë„ ì ìˆ˜(score)** ê³„ì‚°  \n",
    "4. ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ê·¸ ë‹¨ì–´ì˜ **Value**ë¥¼ ë” ë§ì´ ë°˜ì˜  \n",
    "\n",
    "â†’ ì¦‰, ëª¨ë¸ì´ **ê´€ë ¨ ìˆëŠ” ë‹¨ì–´ë§Œ ê³¨ë¼ë‚´ëŠ” ê³¼ì •**ì´ì•¼.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4ï¸âƒ£ Score(ìœ ì‚¬ë„) + Softmax(ì •ê·œí™”)\n",
    "\n",
    "#### âœ”ï¸ í•µì‹¬ ê°œë…\n",
    "- **Score** = Queryì™€ Keyê°€ ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œì§€  \n",
    "- **Softmax** = ì´ ì ìˆ˜ë“¤ì„ 0~1 ì‚¬ì´ **í™•ë¥ ì²˜ëŸ¼ ì •ë¦¬**\n",
    "\n",
    "#### âœ”ï¸ ê²°ê³¼ ì˜ˆì‹œ\n",
    "- ë‹¨ì–´ A : 70% ì¤‘ìš”  \n",
    "- ë‹¨ì–´ B : 20%  \n",
    "- ë‹¨ì–´ C : 10%  \n",
    "\n",
    "â†’ ì´ë ‡ê²Œ **ì¤‘ìš”í•œ ë‹¨ì–´ê°€ í•œëˆˆì— ë³´ì´ë„ë¡ ì •ê·œí™”**í•˜ëŠ” ê³¼ì •.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5ï¸âƒ£ Context ë²¡í„° â€” ìˆœê°„ìˆœê°„ ìƒˆë¡œ ë§Œë“œëŠ” ìš”ì•½ë³¸\n",
    "\n",
    "Seq2SeqëŠ” í•˜ë‚˜ì˜ ìš”ì•½ë§Œ ì‚¬ìš©í–ˆë‹¤ë©´,  \n",
    "Attentionì€ **ë‹¨ì–´ë§ˆë‹¤ ë‹¤ë¥¸ ìš”ì•½(Context vector)ì„ ìƒì„±í•¨.**\n",
    "\n",
    "#### âœ”ï¸ ë¹„ìœ \n",
    "ë¬¸ì œ í•˜ë‚˜ í’€ ë•Œë§ˆë‹¤  \n",
    "êµê³¼ì„œì—ì„œ **í•„ìš”í•œ ë¶€ë¶„ë§Œ ê³¨ë¼ ë‹¤ì‹œ ì½ëŠ” ê²ƒ**ê³¼ ê°™ì•„.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6ï¸âƒ£ Attentionì„ ë¶™ì¸ Seq2Seq â€” êµ¬ì¡° ë³€í™”\n",
    "\n",
    "#### âœ”ï¸ í•µì‹¬ ë³€í™”\n",
    "ë””ì½”ë”ëŠ” ì´ì œ  \n",
    "> **ë‹¨ì–´ë¥¼ ìƒì„±í•  ë•Œë§ˆë‹¤ ì¸ì½”ë”ì˜ ëª¨ë“  ë‹¨ì–´ë¥¼ ë‹¤ì‹œ ì°¸ê³ í•  ìˆ˜ ìˆìŒ.**\n",
    "\n",
    "ì¦‰,  \n",
    "í•œ ë²ˆ ìš”ì•½í•˜ê³  ëì´ ì•„ë‹ˆë¼  \n",
    "í•„ìš”í•  ë•Œë§ˆë‹¤ ê³„ì† ì°¸ê³ í•˜ëŠ” êµ¬ì¡°ë¡œ ë°œì „í•¨.\n",
    "\n",
    "---\n",
    "\n",
    "#### 7ï¸âƒ£ Self-Attention â€” ë‹¨ì–´ë¼ë¦¬ ì„œë¡œ ë°”ë¼ë³´ê¸°\n",
    "\n",
    "#### âœ”ï¸ í•µì‹¬ ê°œë…\n",
    "TransformerëŠ” Attentionì„ í™•ì¥í•´  \n",
    "**ë¬¸ì¥ ë‚´ë¶€ ë‹¨ì–´ë¼ë¦¬ ì„œë¡œ ê´€ë ¨ë„ë¥¼ ê³„ì‚°**í•˜ê²Œ ë§Œë“  êµ¬ì¡°ì•¼.\n",
    "\n",
    "#### âœ”ï¸ ì˜ˆì‹œ\n",
    "ë¬¸ì¥: â€œë‚˜ëŠ” ì˜¤ëŠ˜ ì•„ì¹¨ì— ì‚¬ê³¼ë¥¼ ë¨¹ì—ˆë‹¤â€\n",
    "\n",
    "- â€˜ë¨¹ì—ˆë‹¤â€™ â†” â€˜ì‚¬ê³¼â€™  \n",
    "- â€˜ì˜¤ëŠ˜â€™ â†” â€˜ì•„ì¹¨â€™  \n",
    "\n",
    "ì´ì²˜ëŸ¼ ì„œë¡œ ë©€ë¦¬ ìˆëŠ” ë‹¨ì–´ ê°„ì˜ ê´€ê³„ë„ íŒŒì•…í•  ìˆ˜ ìˆìŒ.\n",
    "\n",
    "---\n",
    "\n",
    "#### 8ï¸âƒ£ ì™œ ì¤‘ìš”í•œê°€? â€” ì‹¤ì§ˆì  í™œìš©\n",
    "\n",
    "AIê°€ ì•„ë˜ ì‘ì—…ë“¤ì„ ë” ì •í™•í•˜ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•¨:\n",
    "\n",
    "- ë²ˆì—­  \n",
    "- ìš”ì•½  \n",
    "- ê°ì • ë¶„ì„  \n",
    "- ì´ë¯¸ì§€ ì„¤ëª…  \n",
    "- ì§ˆì˜ì‘ë‹µ  \n",
    "- ì±—ë´‡ ìƒì„±  \n",
    "\n",
    "í˜„ëŒ€ ëª¨ë¸ì¸ **GPT, BERT, Transformer**ì˜ ê¸°ë°˜ì´ ëª¨ë‘ Attention êµ¬ì¡°ì•¼.\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ”¥ ì „ì²´ í•µì‹¬ ì •ë¦¬\n",
    "\n",
    "- Seq2SeqëŠ” ê¸´ ë¬¸ì¥ì—ì„œ ì •ë³´ê°€ ì†ì‹¤ë¨  \n",
    "- Attentionì€ â€œì§€ê¸ˆ í•„ìš”í•œ ë¶€ë¶„ì— ì§‘ì¤‘â€í•˜ëŠ” ê¸°ìˆ   \n",
    "- Queryâ€“Keyâ€“Value êµ¬ì¡°ë¡œ ì–´ë–¤ ë‹¨ì–´ê°€ ì¤‘ìš”í•œì§€ ê³„ì‚°  \n",
    "- Softmaxë¡œ ì¤‘ìš”ë„ë¥¼ í™•ë¥ ì²˜ëŸ¼ ì •ë¦¬  \n",
    "- ContextëŠ” ë‹¨ì–´ë§ˆë‹¤ ìƒˆë¡œ ë§Œë“œëŠ” ì‘ì€ ìš”ì•½  \n",
    "- Self-Attentionì€ ë‹¨ì–´ë¼ë¦¬ ì„œë¡œ ë³´ë„ë¡ í•¨  \n",
    "- TransformerëŠ” Attention ê¸°ìˆ ì˜ í™•ì¥íŒ ëª¨ë¸  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì¥ì´ ê¸¸ë©´ CPUì—ì„œ ì˜¤ë¥˜ê°€ ë‚  ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f261e1",
   "metadata": {},
   "source": [
    "- ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9a660d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ì–´ ì–´íœ˜ í¬ê¸° : 17\n",
      "í”„ë‘ìŠ¤ì–´ ì–´íœ˜ í¬ê¸° : 20\n",
      "ì˜ì–´ ìµœëŒ€ ê¸¸ì´ : 4\n",
      "í”„ë‘ìŠ¤ì–´ ìµœëŒ€ ê¸¸ì´ : 6\n",
      "ì˜ì–´ íŒ¨ë”© ì²«ë²ˆì¨° : [0 4 5 2]\n",
      "í”„ë‘ìŠ¤ì–´ íŒ¨ë”© ì²«ë²ˆì¨° : [0 2 5 6 4 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "english_sentences = [\n",
    "    'i love you',\n",
    "    'he is a student',\n",
    "    'she likes music',\n",
    "    'we are learning attention',\n",
    "    'you are amazing'\n",
    "]\n",
    "\n",
    "french_sentences = [\n",
    "    '<start> je t aime <end>',\n",
    "    '<start> il est etudiant <end>',\n",
    "    '<start> elle aime la musique <end>',\n",
    "    '<start> nous apprenons l attention <end>',\n",
    "    '<start> tu es incroyable <end>'\n",
    "]\n",
    "\n",
    "# í† í¬ë‚˜ì´ì € ìƒì„±\n",
    "# ë²ˆì—­í•˜ëŠ” ëª¨ë¸ë“¤ì€ ë¬¸ì¥ì˜ ë¶€í˜¸ë‚˜ íŠ¹ìˆ˜ê¸°í˜¸ë¥¼ ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ë¡œ ê°„ì£¼í•´ì•¼í•¨ (I'm fine. VS I'm fine?)\n",
    "eng_tokenizer = Tokenizer(filters='',oov_token='<oov>')\n",
    "fre_tokenizer = Tokenizer(filters='',oov_token='<oov>')\n",
    "\n",
    "eng_tokenizer.fit_on_texts(english_sentences)\n",
    "fre_tokenizer.fit_on_texts(french_sentences)\n",
    "\n",
    "# Sequence ë³€í™˜\n",
    "eng_sequence = eng_tokenizer.texts_to_sequences(english_sentences)\n",
    "fre_sequence = fre_tokenizer.texts_to_sequences(french_sentences)\n",
    "\n",
    "# padding ì£¼ê¸°\n",
    "max_eng_len = max([len(seq) for seq in eng_sequence])\n",
    "max_fre_len = max([len(seq) for seq in fre_sequence])\n",
    "eng_padded = pad_sequences(eng_sequence , max_eng_len)\n",
    "fre_padded = pad_sequences(fre_sequence , max_fre_len)\n",
    "\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1 # keras ì˜ tokenizer ì¸ë±ìŠ¤ë¥¼ 1ë¶€í„° ë¶€ì—¬\n",
    "fre_vocab_size = len(fre_tokenizer.word_index) + 1\n",
    "\n",
    "print(f'ì˜ì–´ ì–´íœ˜ í¬ê¸° : {eng_vocab_size}')\n",
    "print(f'í”„ë‘ìŠ¤ì–´ ì–´íœ˜ í¬ê¸° : {fre_vocab_size}')\n",
    "print(f'ì˜ì–´ ìµœëŒ€ ê¸¸ì´ : {max_eng_len}')\n",
    "print(f'í”„ë‘ìŠ¤ì–´ ìµœëŒ€ ê¸¸ì´ : {max_fre_len}')\n",
    "print(f'ì˜ì–´ íŒ¨ë”© ì²«ë²ˆì¨° : {eng_padded[0]}')\n",
    "print(f'í”„ë‘ìŠ¤ì–´ íŒ¨ë”© ì²«ë²ˆì¨° : {fre_padded[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa90406c",
   "metadata": {},
   "source": [
    "### Seq2Seq ê¸°ë³¸ êµ¬ì¡° (LSTM ê¸°ë°˜)\n",
    "\n",
    "#### 1. ì „ì²´ ê°œë…\n",
    "Seq2SeqëŠ” ì…ë ¥ ë¬¸ì¥ì„ Encoderê°€ ì½ê³  ìš”ì•½í•œ ë’¤,\n",
    "Decoderê°€ ì´ ì •ë³´ë¥¼ ì‚¬ìš©í•´ ìƒˆë¡œìš´ ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” êµ¬ì¡°ì´ë‹¤.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Encoder\n",
    "- ì…ë ¥ ë¬¸ì¥ì„ ìˆœì„œëŒ€ë¡œ ì½ê³  ìš”ì•½í•œë‹¤.\n",
    "- ë§ˆì§€ë§‰ hidden state, cell stateë¥¼ â€œë¬¸ì¥ ìš”ì•½ë³¸â€ì²˜ëŸ¼ ì €ì¥í•œë‹¤.\n",
    "- ì´ ìƒíƒœëŠ” Decoderì˜ ì´ˆê¸°ê°’(Initial State)ë¡œ ì „ë‹¬ëœë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Decoder\n",
    "- Encoderê°€ ì „ë‹¬í•œ ë§ˆì§€ë§‰ ìƒíƒœ(state_h, state_c)ë¥¼ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.\n",
    "- ì´ì „ì— ìƒì„±ëœ ë‹¨ì–´ì™€ Context ì •ë³´ë¥¼ ì´ìš©í•´ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•œë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. LSTMì˜ ì£¼ìš” ì˜µì…˜ ë° ì¶œë ¥\n",
    "\n",
    "#### return_sequences = True\n",
    "- ëª¨ë“  íƒ€ì„ìŠ¤í…ì˜ hidden stateë¥¼ ë°˜í™˜í•œë‹¤.\n",
    "- Attention ê³„ì‚°ì— í•„ìˆ˜ì´ë‹¤.\n",
    "\n",
    "#### encoder_outputs\n",
    "- Encoderì˜ ê° íƒ€ì„ìŠ¤í… hidden state ì „ì²´.\n",
    "- Attentionì—ì„œ Key/Valueë¡œ ì‚¬ìš©ëœë‹¤.\n",
    "\n",
    "#### encoder_state (state_h, state_c)\n",
    "- Encoderì˜ ë§ˆì§€ë§‰ hidden/cell state.\n",
    "- Decoderê°€ ì²˜ìŒ ì‚¬ìš©í•  ì´ˆê¸° ìƒíƒœ(Initial State).\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. êµ¬ì¡° (ASCII ë‹¤ì´ì–´ê·¸ë¨)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. ì¶”ê°€ë¡œ ê¼­ ì•Œì•„ì•¼ í•˜ëŠ” ë‚´ìš©\n",
    "\n",
    "#### ì™œ Attentionì´ í•„ìš”í•œê°€?\n",
    "- ê¸°ì¡´ Seq2SeqëŠ” ë§ˆì§€ë§‰ hidden state í•˜ë‚˜ë¡œë§Œ ë¬¸ì¥ì„ ìš”ì•½í–ˆë‹¤.\n",
    "- ê¸´ ë¬¸ì¥ì€ ì •ë³´ê°€ ë§ì´ ì†ì‹¤ëœë‹¤.\n",
    "- Decoderê°€ Encoderì˜ ëª¨ë“  ë‹¨ì–´(hidden state)ë¥¼ ì°¸ê³ í•˜ë„ë¡ Attentionì´ ë„ì…ë˜ì—ˆë‹¤.\n",
    "\n",
    "#### Encoder ì¶œë ¥ 2ì¢…ë¥˜ ìš”ì•½\n",
    "\n",
    "| ì´ë¦„ | ì˜ë¯¸ | Attention ì‚¬ìš© ì—¬ë¶€ |\n",
    "|------|------|----------------------|\n",
    "| encoder_outputs | ì „ì²´ hidden state | ì‚¬ìš©ë¨ (Key/Value) |\n",
    "| encoder_state   | ë§ˆì§€ë§‰ hidden/cell | ì‚¬ìš©ë˜ì§€ ì•ŠìŒ (Decoder ì´ˆê¸°ê°’ë§Œ ë‹´ë‹¹) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc82f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Encoder êµ¬ì„± ì™„ë£Œ\n",
      "   - Encoder Outputs Shape: (batch, 4, 128)\n",
      "   - Hidden State Shape: (batch, 128)\n",
      "   - Cell State Shape: (batch, 128)\n",
      "âœ… Decoder êµ¬ì„± ì™„ë£Œ\n",
      "   - Decoder Outputs Shape: (batch, 6, 128)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input , LSTM , Dense , Embedding , Layer\n",
    "# Functional API\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "embedding_dim = 64\n",
    "units = 128\n",
    "\n",
    "# ========== ENCODER ==========\n",
    "encoder_inputs = Input(shape=(max_eng_len,), name='encoder_input')\n",
    "encoder_embedding = Embedding(eng_vocab_size, embedding_dim, name='encoder_embedding')(encoder_inputs)\n",
    "\n",
    "# return_sequences=True: ëª¨ë“  íƒ€ì„ìŠ¤í…ì˜ hidden state ë°˜í™˜ (Attention ê³„ì‚°ì— í•„ìš”)\n",
    "# return_state=True: ë§ˆì§€ë§‰ hidden stateì™€ cell state ë°˜í™˜ (Decoder ì´ˆê¸°í™”ì— ì‚¬ìš©)\n",
    "encoder_lstm = LSTM(units, return_sequences=True, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "\n",
    "# encoder_states = [state_h, state_c]ëŠ” Decoderì˜ ì´ˆê¸° ìƒíƒœë¡œ ì „ë‹¬\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "print(f\"âœ… Encoder êµ¬ì„± ì™„ë£Œ\")\n",
    "print(f\"   - Encoder Outputs Shape: (batch, {max_eng_len}, {units})\")\n",
    "print(f\"   - Hidden State Shape: (batch, {units})\")\n",
    "print(f\"   - Cell State Shape: (batch, {units})\")\n",
    "\n",
    "# ========== DECODER ==========\n",
    "decoder_inputs = Input(shape=(max_fre_len,), name='decoder_input')\n",
    "decoder_embedding = Embedding(fre_vocab_size, embedding_dim, name='decoder_embedding')(decoder_inputs)\n",
    "\n",
    "# return_sequences=True: ëª¨ë“  íƒ€ì„ìŠ¤í… ì¶œë ¥ (ê° ì‹œì ë§ˆë‹¤ Attention ì ìš©)\n",
    "# return_state=True: Inference ì‹œ ìƒíƒœ ì „ë‹¬ìš©\n",
    "decoder_lstm = LSTM(units, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "print(f\"âœ… Decoder êµ¬ì„± ì™„ë£Œ\")\n",
    "print(f\"   - Decoder Outputs Shape: (batch, {max_fre_len}, {units})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b7e5c",
   "metadata": {},
   "source": [
    "- ë””ì½”ë”ì˜ í˜„ì¬ìƒíƒœ(query)ì™€ ì¸ì½”ë”ì˜ ëª¨ë“  íˆë“ ìŠ¤í…Œ (value / keys)ë¥¼ ë¹„êµí•´ì„œ\n",
    "- ê° ì¸ì½”ë” íƒ€ì„ìŠ¤í…ì— ëŒ€í•œ ì¤‘ìš”ë„(ê°€ì¤‘ì¹˜)ë¥¼ ê³„ì‚°í•˜ê³ , ê·¸ ê°€ì¤‘ì¹˜ë¡œ ì¸ì½”ë” ì¶œë ¥ì„ ê°€ì¤‘í•©í•´ context vectorì„ ì–»ëŠ”ë‹¤\n",
    "\n",
    "#### ì–´í…ì…˜ ë ˆì´ì–´ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3296697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CAttention name=attention, built=False>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CAttention(Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(CAttention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "    def build(self, input_shape):\n",
    "        # W1: Query ë³€í™˜ ê°€ì¤‘ì¹˜ (decoder hidden state â†’ attention space)\n",
    "        self.W1 = self.add_weight(name='W1',\n",
    "                                shape=(input_shape[0][-1], self.units),\n",
    "                                initializer='glorot_uniform',\n",
    "                                trainable=True)\n",
    "    \n",
    "        # W2: Key ë³€í™˜ ê°€ì¤‘ì¹˜ (encoder hidden states â†’ attention space)\n",
    "        self.W2 = self.add_weight(name='W2',\n",
    "                                shape=(input_shape[1][-1], self.units),\n",
    "                                initializer='glorot_uniform',\n",
    "                                trainable=True)\n",
    "        \n",
    "        # V: Scoreë¥¼ ìŠ¤ì¹¼ë¼ë¡œ ë³€í™˜\n",
    "        self.V = self.add_weight(name='V',\n",
    "                                shape=(self.units, 1),\n",
    "                                initializer='glorot_uniform',\n",
    "                                trainable=True)\n",
    "        super(CAttention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query: Decoder hidden state (batch, decoder_units)\n",
    "            values: Encoder hidden states (batch, max_eng_len, encoder_units)\n",
    "        \n",
    "        Returns:\n",
    "            context_vector: (batch, encoder_units)\n",
    "            attention_weights: (batch, max_eng_len, 1)\n",
    "        \"\"\"\n",
    "        query, values = inputs\n",
    "        \n",
    "        # Query ì°¨ì› í™•ì¥: (batch, decoder_units) â†’ (batch, 1, decoder_units)\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        \n",
    "        # Score ê³„ì‚°: tanh(W1*Q + W2*K)\n",
    "        # W1*Q: (batch, 1, units)\n",
    "        # W2*K: (batch, max_eng_len, units)\n",
    "        score = tf.nn.tanh(\n",
    "            tf.matmul(query_with_time_axis, self.W1) + tf.matmul(values, self.W2)\n",
    "        )\n",
    "        # score shape: (batch, max_eng_len, units)\n",
    "        \n",
    "        # Vë¥¼ ê³±í•´ì„œ ìŠ¤ì¹¼ë¼ scoreë¡œ ë³€í™˜\n",
    "        attention_logits = tf.matmul(score, self.V)\n",
    "        # shape: (batch, max_eng_len, 1)\n",
    "        \n",
    "        # Softmaxë¡œ í™•ë¥  ë¶„í¬ ë³€í™˜ (í•©ì´ 1)\n",
    "        attention_weights = tf.nn.softmax(attention_logits, axis=1)\n",
    "        \n",
    "        # Context vector ê³„ì‚°: ê°€ì¤‘ í•©\n",
    "        # attention_weights: (batch, max_eng_len, 1)\n",
    "        # values: (batch, max_eng_len, encoder_units)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        # shape: (batch, encoder_units)\n",
    "        \n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config\n",
    "    \n",
    "# Attention Layer\n",
    "attention_layer = CAttention(units=10, name='attention')\n",
    "attention_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a60563",
   "metadata": {},
   "source": [
    "Attentioní†µí•©ëª¨ë¸\n",
    "\n",
    "decoderì— Attentionì„ ì ìš©í•´ì„œ Context Vectorì™€ ê²°í•©\n",
    "\n",
    "ê° ë””ì½”ë” ë‹¤ì„ìŠ¤í…ë§ˆë‹¤ Attention ê³„ì‚°\n",
    "\n",
    "Context Vector + Decoder Outputì„ Concatenateí•´ì„œ ì˜ˆì¸¡ì •í™•ë„ ë†’ì„\n",
    "\n",
    "TimeDistriubted : ëª¨ë“  íƒ€ì„ìŠ¤í…ì— ë™ì¼í•œ Dense Layerì ìš©\n",
    "\n",
    "Lmbda ë ˆì´ì–´ë¡œ ê° íƒ€ì„ìŠ¤í…ì˜ hidden state ì¶”ì¶œí›„ Attentionì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f86a5d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Context Vector Shape: (batch, 6, 128)\n",
      "   - Combined Shape: (batch, 6, 256)\n",
      "   - Output Shape: (batch, 6, 20)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Concatenate,Dense,Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Attentionì„ ê° ë””ì½”ë” íƒ€ì„ìŠ¤í…ì— ì ìš©\n",
    "def apply_attention(inputs):\n",
    "    \"\"\"\n",
    "    ê° íƒ€ì„ìŠ¤í…ë§ˆë‹¤ Attention ê³„ì‚°\n",
    "    \"\"\"\n",
    "    encoder_outputs, decoder_outputs = inputs\n",
    "    \n",
    "    # íƒ€ì„ìŠ¤í…ë³„ë¡œ ìˆœíšŒí•˜ë©° Context Vector ìƒì„±\n",
    "    context_vectors = []\n",
    "    attention_weights_list = []\n",
    "    \n",
    "    for t in range(max_fre_len):\n",
    "        # t ì‹œì ì˜ decoder hidden state ì¶”ì¶œ\n",
    "        decoder_hidden_t = decoder_outputs[:, t, :]\n",
    "        \n",
    "        # Attention ê³„ì‚°\n",
    "        context_vector, attention_weights = attention_layer([decoder_hidden_t, encoder_outputs])\n",
    "        context_vectors.append(context_vector)\n",
    "        attention_weights_list.append(attention_weights)\n",
    "    \n",
    "    # (batch, max_fra_len, encoder_units)ë¡œ ì¬êµ¬ì„±\n",
    "    context_vectors = tf.stack(context_vectors, axis=1)\n",
    "    attention_weights_all = tf.stack(attention_weights_list, axis=1)\n",
    "    \n",
    "    return context_vectors, attention_weights_all\n",
    "\n",
    "\n",
    "# Lambda Layerë¡œ ë˜í•‘\n",
    "attention_result = Lambda(apply_attention, name='apply_attention')([encoder_outputs, decoder_outputs])\n",
    "context_vectors, attention_weights_all = attention_result[0], attention_result[1]\n",
    "\n",
    "# Decoder Output + Context Vector ê²°í•©\n",
    "decoder_combined = Concatenate(axis=-1, name='concat')([decoder_outputs, context_vectors])\n",
    "\n",
    "# ìµœì¢… ì¶œë ¥ ë ˆì´ì–´ (ë‹¨ì–´ í™•ë¥  ë¶„í¬)\n",
    "output_layer = Dense(fre_vocab_size, activation='softmax', name='output')\n",
    "outputs = output_layer(decoder_combined)\n",
    "\n",
    "\n",
    "print(f\"   - Context Vector Shape: (batch, {max_fre_len}, {units})\")\n",
    "print(f\"   - Combined Shape: (batch, {max_fre_len}, {units * 2})\")\n",
    "print(f\"   - Output Shape: (batch, {max_fre_len}, {fre_vocab_size})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb6436",
   "metadata": {},
   "source": [
    "ëª¨ë¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf65cd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"attention seq2seq\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"attention seq2seq\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_embedding   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> â”‚ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_embedding   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> â”‚ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> â”‚ encoder_embeddinâ€¦ â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      â”‚            â”‚                   â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> â”‚ decoder_embeddinâ€¦ â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      â”‚            â”‚ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      â”‚            â”‚ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ apply_attention     â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)]  â”‚            â”‚ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concat              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ apply_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,140</span> â”‚ concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_embedding   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚      \u001b[38;5;34m1,088\u001b[0m â”‚ encoder_input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_embedding   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚      \u001b[38;5;34m1,280\u001b[0m â”‚ decoder_input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m),  â”‚     \u001b[38;5;34m98,816\u001b[0m â”‚ encoder_embeddinâ€¦ â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      â”‚            â”‚                   â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m),  â”‚     \u001b[38;5;34m98,816\u001b[0m â”‚ decoder_embeddinâ€¦ â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      â”‚            â”‚ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      â”‚            â”‚ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ apply_attention     â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m),  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mLambda\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1\u001b[0m)]  â”‚            â”‚ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concat              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ apply_attention[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m20\u001b[0m)     â”‚      \u001b[38;5;34m5,140\u001b[0m â”‚ concat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,140</span> (801.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m205,140\u001b[0m (801.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,140</span> (801.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m205,140\u001b[0m (801.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model([encoder_inputs,decoder_inputs], outputs,name = 'attention seq2seq')\n",
    "model.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
