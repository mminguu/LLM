{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84b6f889",
   "metadata": {},
   "source": [
    "### ğŸ§© í† í”½ ëª¨ë¸ë§ (Topic Modeling)\n",
    "#### ğŸ§  LDA(Latent Dirichlet Allocation)ë€?\n",
    "- ì—¬ëŸ¬ ë¬¸ì„œ ì•ˆì— ìˆ¨ê²¨ì§„ ì£¼ì œ(Topic) ë“¤ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ë‚´ëŠ” ìƒì„± í™•ë¥  ëª¨ë¸\n",
    "- â€œë¬¸ì„œëŠ” ì—¬ëŸ¬ ì£¼ì œì˜ í˜¼í•©ìœ¼ë¡œ ë˜ì–´ ìˆê³ , ê° ì£¼ì œëŠ” íŠ¹ì • ë‹¨ì–´ë“¤ì˜ ë¶„í¬ë¡œ ì´ë£¨ì–´ì§„ë‹¤â€ëŠ” ê°€ì •ì— ê¸°ë°˜í•¨.\n",
    "\n",
    "| êµ¬ì„± ìš”ì†Œ             | ì„¤ëª…                         |\n",
    "| ----------------- | -------------------------- |\n",
    "| **Document (ë¬¸ì„œ)** | ì—¬ëŸ¬ **í† í”½ì˜ í˜¼í•©**ìœ¼ë¡œ êµ¬ì„±ëœ í•˜ë‚˜ì˜ ë¬¸ì„œ |\n",
    "| **Topic (ì£¼ì œ)**    | ì—¬ëŸ¬ **ë‹¨ì–´ë“¤ì˜ í™•ë¥  ë¶„í¬**ë¡œ í‘œí˜„ë¨     |\n",
    "| **Word (ë‹¨ì–´)**     | íŠ¹ì • **í† í”½**ìœ¼ë¡œë¶€í„° ìƒì„±ëœ ë‹¨ì–´       |\n",
    "\n",
    "\n",
    "| êµ¬ì„± ìš”ì†Œ             | ì„¤ëª…                         |\n",
    "| ----------------- | -------------------------- |\n",
    "| **Document (ë¬¸ì„œ)** | ì—¬ëŸ¬ **í† í”½ì˜ í˜¼í•©**ìœ¼ë¡œ êµ¬ì„±ëœ í•˜ë‚˜ì˜ ë¬¸ì„œ |\n",
    "| **Topic (ì£¼ì œ)**    | ì—¬ëŸ¬ **ë‹¨ì–´ë“¤ì˜ í™•ë¥  ë¶„í¬**ë¡œ í‘œí˜„ë¨     |\n",
    "| **Word (ë‹¨ì–´)**     | íŠ¹ì • **í† í”½**ìœ¼ë¡œë¶€í„° ìƒì„±ëœ ë‹¨ì–´       |\n",
    "\n",
    "\n",
    "#### âš™ï¸ LDA ë™ì‘ ì›ë¦¬ (ê°„ë‹¨ íë¦„)\n",
    "1. ëª¨ë“  ë¬¸ì„œë¥¼ ì—¬ëŸ¬ í† í”½ì˜ í˜¼í•©ìœ¼ë¡œ ê°€ì •\n",
    "2. ê° í† í”½ì€ ë‹¨ì–´ì˜ í™•ë¥  ë¶„í¬ë¥¼ ê°€ì§\n",
    "3. ë¬¸ì„œë§ˆë‹¤ í† í”½ ë¹„ìœ¨ê³¼ ë‹¨ì–´ ë¶„í¬ë¥¼ ë¬´ì‘ìœ„ë¡œ ì´ˆê¸°í™”\n",
    "4. ë°˜ë³µì ìœ¼ë¡œ ì•„ë˜ ê³¼ì • ìˆ˜í–‰\n",
    "5. ê° ë‹¨ì–´ê°€ ì–´ë–¤ í† í”½ì—ì„œ ë‚˜ì™”ëŠ”ì§€ ì¶”ì •\n",
    "6. ë¬¸ì„œì˜ í† í”½ ë¹„ìœ¨ ì—…ë°ì´íŠ¸\n",
    "7. í† í”½ë³„ ë‹¨ì–´ ë¶„í¬ ì—…ë°ì´íŠ¸\n",
    "8. ìˆ˜ë ´í•˜ë©´ â†’ ë¬¸ì„œë³„ ì£¼ìš” í† í”½, í† í”½ë³„ ì£¼ìš” ë‹¨ì–´ê°€ ë„ì¶œë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b6ac4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in /Users/anaconda3/lib/python3.13/site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /Users/anaconda3/lib/python3.13/site-packages (from konlpy) (1.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /Users/anaconda3/lib/python3.13/site-packages (from konlpy) (5.3.0)\n",
      "Requirement already satisfied: numpy>=1.6 in /Users/anaconda3/lib/python3.13/site-packages (from konlpy) (2.1.3)\n",
      "Requirement already satisfied: packaging in /Users/anaconda3/lib/python3.13/site-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d27815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì„œ ë‹¨ì–´ í–‰ë ¬ : (8, 36)\n",
      "ë‹¨ì–´ ëª©ë¡ : ['nlpë¼ê³ ë„' 'python' 'ê°•ë ¥í•˜ê³ ' 'ê¸°ë°˜í•©ë‹ˆë‹¤' 'ê¸°ìˆ ì€' 'ê¸°ìˆ ì…ë‹ˆë‹¤' 'ë°ì´í„°' 'ë”¥ëŸ¬ë‹ì€' 'ë§Œë“¤' 'ë§¤ìš°'\n",
      " 'ë¨¸ì‹ ëŸ¬ë‹' 'ë¨¸ì‹ ëŸ¬ë‹ì€' 'ëª¨ë¸ì€' 'ëª¨ë¸ì„' 'ë°œì „í•˜ê³ ' 'ë°©ë²•ì…ë‹ˆë‹¤' 'ë°°ìš°ê¸°' 'ë¶„ì„ì€' 'ë¶ˆë¦½ë‹ˆë‹¤' 'ë¹ ë¥´ê²Œ' 'ì‰¬ì›Œìš”'\n",
      " 'ì‹ ê²½ë§ì„' 'ì´ìš©í•œ' 'ì´í•´í• ' 'ì¸ê³µì§€ëŠ¥' 'ì¸ê³µì§€ëŠ¥ì˜' 'ìˆìŠµë‹ˆë‹¤' 'ìˆì–´ìš”' 'ìì—°ì–´ì²˜ë¦¬' 'ìì—°ì–´ì²˜ë¦¬ëŠ”' 'í…ìŠ¤íŠ¸ë¥¼'\n",
      " 'í†µê³„í•™ì—' 'íŒŒì´ì¬ìœ¼ë¡œ' 'í”„ë¡œê·¸ë˜ë°ì€' 'í•™ìŠµ' 'í•µì‹¬']  /  ë‹¨ì–´ ëª©ë¡ ê°œìˆ˜ : 36\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import matplotlib.pyplot as plt\n",
    "from konlpy.tag import Okt\n",
    "import konlpy\n",
    "\n",
    "documents = [\n",
    "    \"Python í”„ë¡œê·¸ë˜ë°ì€ ë§¤ìš° ê°•ë ¥í•˜ê³  ë°°ìš°ê¸° ì‰¬ì›Œìš”\",\n",
    "    \"ë¨¸ì‹ ëŸ¬ë‹ì€ ì¸ê³µì§€ëŠ¥ì˜ í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤\",\n",
    "    \"ìì—°ì–´ì²˜ë¦¬ëŠ” NLPë¼ê³ ë„ ë¶ˆë¦½ë‹ˆë‹¤\",\n",
    "    \"ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì„ ì´ìš©í•œ í•™ìŠµ ë°©ë²•ì…ë‹ˆë‹¤\",\n",
    "    \"ë°ì´í„° ë¶„ì„ì€ í†µê³„í•™ì— ê¸°ë°˜í•©ë‹ˆë‹¤\",\n",
    "    \"íŒŒì´ì¬ìœ¼ë¡œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤\",\n",
    "    \"ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì€ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤\",\n",
    "    \"ìì—°ì–´ì²˜ë¦¬ ëª¨ë¸ì€ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•  ìˆ˜ ìˆì–´ìš”\"\n",
    "]\n",
    "\n",
    "# ë‹¨ì–´ ë²¡í„°í™”\n",
    "cv = CountVectorizer(\n",
    "    max_features=50,\n",
    "    stop_words = ['ì€','ëŠ”','ì´','ê°€','ì„','ë¥¼','ê·¸','ê·¸ë¦¬ê³ '],\n",
    "    min_df=1,\n",
    "    max_df=0.9\n",
    ")\n",
    "doc_term_matrix = cv.fit_transform(documents)\n",
    "feature_names = cv.get_feature_names_out()\n",
    "print(f'ë¬¸ì„œ ë‹¨ì–´ í–‰ë ¬ : {doc_term_matrix.shape}')\n",
    "print(f'ë‹¨ì–´ ëª©ë¡ : {feature_names}  /  ë‹¨ì–´ ëª©ë¡ ê°œìˆ˜ : {len(feature_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df0c3704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì„œ-ì£¼ì œ í–‰ë ¬ : (8, 3)\n",
      "ì²«ë²ˆì§¸ ë¬¸ì„œì˜ ì£¼ì œ ë¶„í¬\n",
      "Topic 0: 0.0481\n",
      "Topic 1: 0.0483\n",
      "Topic 2: 0.9036\n",
      "ê° ì£¼ì œë³„ ìƒìœ„ ë‹¨ì–´----\n",
      "[topic 0]\n",
      "  ê¸°ìˆ ì€ : 1.3185\n",
      "  ëª¨ë¸ì€ : 1.3178\n",
      "  í•µì‹¬ : 1.3125\n",
      "  ì¸ê³µì§€ëŠ¥ : 1.3124\n",
      "  ê¸°ìˆ ì…ë‹ˆë‹¤ : 1.3116\n",
      "\n",
      "[topic 1]\n",
      "  ìˆìŠµë‹ˆë‹¤ : 1.3128\n",
      "  ëª¨ë¸ì„ : 1.3109\n",
      "  ë°ì´í„° : 1.3104\n",
      "  ë¶„ì„ì€ : 1.3095\n",
      "  ë¨¸ì‹ ëŸ¬ë‹ : 1.3091\n",
      "\n",
      "[topic 2]\n",
      "  ë§¤ìš° : 1.3191\n",
      "  ê°•ë ¥í•˜ê³  : 1.3182\n",
      "  python : 1.3135\n",
      "  nlpë¼ê³ ë„ : 1.3131\n",
      "  ë°°ìš°ê¸° : 1.3099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LDA ëª¨ë¸ ìƒì„±\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda_model =  LatentDirichletAllocation(\n",
    "    n_components=3  # í† í”½(ì£¼ì œ) ê°œìˆ˜\n",
    "    ,random_state=42\n",
    "    ,max_iter=20\n",
    "    ,learning_method='online'   # batch (ëª¨ë“ ë°ì´í„°ë¥¼ í•œë²ˆì— ë‹¤ì¨ì„œ í•œë²ˆí•™ìŠµ), online(ë¯¸ë‹ˆë°°ì¹˜)\n",
    ")\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "lda_output = lda_model.fit_transform(doc_term_matrix)\n",
    "print(f'ë¬¸ì„œ-ì£¼ì œ í–‰ë ¬ : {lda_output.shape}')\n",
    "print(f'ì²«ë²ˆì§¸ ë¬¸ì„œì˜ ì£¼ì œ ë¶„í¬')\n",
    "print(f'Topic 0: {lda_output[0,0]:.4f}')\n",
    "print(f'Topic 1: {lda_output[0,1]:.4f}')\n",
    "print(f'Topic 2: {lda_output[0,2]:.4f}')\n",
    "\n",
    "# ê° ì£¼ì œë³„ë¡œ ìƒìœ„ ë‹¨ì–´ ì¶œë ¥\n",
    "def display_topic(model, feature_nams, n_top_words = 5):\n",
    "    print(f'ê° ì£¼ì œë³„ ìƒìœ„ ë‹¨ì–´----')\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        # ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ ë‹¨ì–´ì˜ ì¸ë±ìŠ¤ í˜¸ì¶œ\n",
    "        top_words_idx = topic.argsort()[-n_top_words:][::-1]\n",
    "        top_words = [ feature_nams[i] for i in top_words_idx]\n",
    "        top_weights = [ topic[i] for i in top_words_idx ]\n",
    "        print(f'[topic {topic_idx}]')\n",
    "        for word,weight in zip(top_words,top_weights):\n",
    "            print(f'  {word} : {weight:.4f}')\n",
    "        print()\n",
    "display_topic(lda_model, feature_names,n_top_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "096c72b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9036180312192277)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_output[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4a55bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê° ë¬¸ì„œì˜ ì¤‘ìš” ì£¼ì œ - - - - - - - - -\n",
      "ë¬¸ì„œ : 0 topic : 2 ë¹„ìœ¨ : 0.9036\n",
      "ì›ë¬¸ : Python í”„ë¡œê·¸ë˜ë°ì€ ë§¤ìš° ê°•ë ¥í•˜ê³  ë°°ìš°ê¸° ì‰¬ì›Œìš”\n",
      "ë¬¸ì„œ : 1 topic : 0 ë¹„ìœ¨ : 0.8650\n",
      "ì›ë¬¸ : ë¨¸ì‹ ëŸ¬ë‹ì€ ì¸ê³µì§€ëŠ¥ì˜ í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤\n",
      "ë¬¸ì„œ : 2 topic : 2 ë¹„ìœ¨ : 0.8312\n",
      "ì›ë¬¸ : ìì—°ì–´ì²˜ë¦¬ëŠ” NLPë¼ê³ ë„ ë¶ˆë¦½ë‹ˆë‹¤\n",
      "ë¬¸ì„œ : 3 topic : 2 ë¹„ìœ¨ : 0.8876\n",
      "ì›ë¬¸ : ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì„ ì´ìš©í•œ í•™ìŠµ ë°©ë²•ì…ë‹ˆë‹¤\n",
      "ë¬¸ì„œ : 4 topic : 1 ë¹„ìœ¨ : 0.8655\n",
      "ì›ë¬¸ : ë°ì´í„° ë¶„ì„ì€ í†µê³„í•™ì— ê¸°ë°˜í•©ë‹ˆë‹¤\n",
      "ë¬¸ì„œ : 5 topic : 1 ë¹„ìœ¨ : 0.8867\n",
      "ì›ë¬¸ : íŒŒì´ì¬ìœ¼ë¡œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
      "ë¬¸ì„œ : 6 topic : 0 ë¹„ìœ¨ : 0.8855\n",
      "ì›ë¬¸ : ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì€ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤\n",
      "ë¬¸ì„œ : 7 topic : 0 ë¹„ìœ¨ : 0.8876\n",
      "ì›ë¬¸ : ìì—°ì–´ì²˜ë¦¬ ëª¨ë¸ì€ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•  ìˆ˜ ìˆì–´ìš”\n"
     ]
    }
   ],
   "source": [
    "# ê° ë¬¸ì„œì˜ ì£¼ìš” ì£¼ì œ\n",
    "print(f'ê° ë¬¸ì„œì˜ ì¤‘ìš” ì£¼ì œ - - - - - - - - -')\n",
    "for doc_idx , doc in enumerate(lda_output):\n",
    "    main_topic = np.argmax(doc)\n",
    "    confidence = doc[main_topic]\n",
    "    print(f'ë¬¸ì„œ : {doc_idx} topic : {main_topic} ë¹„ìœ¨ : {confidence:.4f}')\n",
    "    print(f'ì›ë¬¸ : {documents[doc_idx]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
